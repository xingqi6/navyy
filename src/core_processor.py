#!/usr/bin/env python3
# Obfuscated: Intelligent Deduplication Stream Processor
from huggingface_hub import HfApi, hf_hub_download
import os
import sys
import time
import json
import re
import shutil
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict

# === é…ç½®åŒºåŸŸ ===
DISK_SAFE_LIMIT_MB = 1024  # 1GB ä¿æŠ¤
# å®šä¹‰éŸ³è´¨ç­‰çº§ï¼Œè¶Šé å‰å“è´¨è¶Šé«˜
QUALITY_HIERARCHY = ['flac24bit', '24bit', 'flac', 'wav', '320', '320k', '192', '128']
# =================

def log(msg):
    print(f"[{datetime.now().strftime('%H:%M:%S')}] [SYNC] {msg}", flush=True)

def get_free_space_mb(folder):
    try:
        total, used, free = shutil.disk_usage(folder)
        return free // (1024 * 1024)
    except: return 999999

def clean_filename(filename):
    """
    æ¸…æ´—æ–‡ä»¶åï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦ä¸ºåŒä¸€é¦–æ­Œã€‚
    å»é™¤ [320], [flac], (Live), åç¼€åç­‰ï¼Œåªä¿ç•™ 'æ­Œæ‰‹/ä¸“è¾‘/æ­Œå'
    """
    # å»é™¤æ‰©å±•å
    base, _ = os.path.splitext(filename)
    # å»é™¤æ–¹æ‹¬å·å†…å®¹ [320], [flac] ç­‰
    base = re.sub(r'\[.*?\]', '', base)
    # å»é™¤åœ†æ‹¬å·å†…å®¹ (Live), (Cover) ç­‰ (å¯é€‰ï¼Œè§†æƒ…å†µè€Œå®šï¼Œè¿™é‡Œåä¿å®ˆï¼Œåªå»ç©ºæ ¼)
    # base = re.sub(r'\(.*?\)', '', base) 
    # å»é™¤å¤šä½™ç©ºæ ¼
    base = base.strip()
    return base.lower()

def get_quality_score(filename, target_pattern):
    """
    è®¡ç®—æ–‡ä»¶ä¼˜å…ˆçº§åˆ†æ•°ã€‚åˆ†æ•°è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜ã€‚
    0: å®Œç¾åŒ¹é…ç”¨æˆ·è¦æ±‚
    1: æ¯”ç”¨æˆ·è¦æ±‚æ›´å¥½
    2: æ¯”ç”¨æˆ·è¦æ±‚æ›´å·®
    3: æœªçŸ¥/å…¶ä»–
    """
    fname = filename.lower()
    target = target_pattern.lower().replace("[", "").replace("]", "").strip() # å»é™¤ç”¨æˆ·è¾“å…¥çš„æ‹¬å·
    
    # 1. å®Œç¾åŒ¹é… (åŒ…å«ç”¨æˆ·æŒ‡å®šçš„å­—ç¬¦)
    if target != "*" and target in fname:
        return 0
    
    # æå–æ–‡ä»¶ä¸­çš„éŸ³è´¨æ ‡è¯†
    file_q_index = 999
    target_q_index = 999
    
    # æ‰¾åˆ°æ–‡ä»¶å½“å‰çš„éŸ³è´¨ç­‰çº§
    for idx, q in enumerate(QUALITY_HIERARCHY):
        if q in fname:
            file_q_index = idx
            break
            
    # æ‰¾åˆ°ç”¨æˆ·ç›®æ ‡çš„éŸ³è´¨ç­‰çº§
    for idx, q in enumerate(QUALITY_HIERARCHY):
        if q in target:
            target_q_index = idx
            break
            
    # å¦‚æœæ²¡æ‰¾åˆ°ç”¨æˆ·çš„ç›®æ ‡ç­‰çº§ï¼Œé»˜è®¤æŠŠæ‰€æœ‰æ–‡ä»¶éƒ½å½“åšâ€œå…¶ä»–â€
    if target_q_index == 999:
        return 3

    # 2. æ¯”è¾ƒéŸ³è´¨
    if file_q_index < target_q_index:
        return 1 # å“è´¨æ›´å¥½ (Indexè¶Šå°å“è´¨è¶Šé«˜)
    else:
        return 2 # å“è´¨æ›´å·®

def get_smart_file_list(api, repo_id, artist_filter, quality_filter):
    """
    è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œå¹¶æ‰§è¡Œå»é‡å’Œä¼˜é€‰é€»è¾‘
    """
    try:
        log(f"æ­£åœ¨è·å–æ–‡ä»¶åˆ—è¡¨å¹¶è®¡ç®—æœ€ä¼˜ç‰ˆæœ¬...")
        all_files = api.list_repo_files(repo_id=repo_id, repo_type="dataset")
        
        # 1. æ­Œæ‰‹/è·¯å¾„åˆç­›
        candidates = []
        artist_rules = [p.strip().lower() for p in artist_filter.split(',') if p.strip()]
        
        for f in all_files:
            if f.endswith(('.gitattributes', 'README.md', '.git', '.json', '.sync_meta')): continue
            
            # æ­Œæ‰‹è¿‡æ»¤
            if artist_filter != "*":
                f_lower = f.lower()
                # ç®€å•åŒ…å«é€»è¾‘ï¼Œæ”¯æŒé€šé…ç¬¦
                if not any((rule.replace("*", "") in f_lower) for rule in artist_rules):
                    continue
            candidates.append(f)

        # 2. åˆ†ç»„å»é‡
        song_groups = defaultdict(list)
        for f in candidates:
            # ä½¿ç”¨æ¸…æ´—åçš„æ–‡ä»¶åä½œä¸º Key (Keyç›¸åŒè§†ä¸ºåŒä¸€é¦–æ­Œ)
            key = clean_filename(f)
            song_groups[key].append(f)
            
        # 3. ç»„å†…ä¼˜é€‰
        final_list = []
        for key, group_files in song_groups.items():
            if len(group_files) == 1:
                final_list.append(group_files[0]) # åªæœ‰è¿™ä¸€ä¸ªï¼Œç›´æ¥ä¸‹
            else:
                # å¤šä¸ªç‰ˆæœ¬ï¼Œå¼€å§‹PK
                # æŒ‰åˆ†æ•°æ’åºï¼šåˆ†æ•°è¶Šå°è¶Šå¥½ (åŒ¹é… > é«˜å“è´¨ > ä½å“è´¨)
                sorted_files = sorted(group_files, key=lambda x: get_quality_score(x, quality_filter))
                winner = sorted_files[0]
                final_list.append(winner)
                # è°ƒè¯•æ—¥å¿—ï¼šæ˜¾ç¤ºé€‰æ‹©ç»“æœ
                # log(f"æ­Œæ›² [{key}] é€‰æ‹©äº†: {os.path.basename(winner)}")

        log(f"æ™ºèƒ½ç­›é€‰: åŸå§‹ {len(all_files)} -> æ­Œæ‰‹åŒ¹é… {len(candidates)} -> æœ€ç»ˆå»é‡å {len(final_list)} é¦–")
        return final_list

    except Exception as e:
        log(f"æ™ºèƒ½åˆ—è¡¨è®¡ç®—å¤±è´¥: {e}")
        return []

def download_single_file(repo_id, filename, token, target_root):
    if get_free_space_mb(target_root) < DISK_SAFE_LIMIT_MB: return "DISK_FULL"
    try:
        hf_hub_download(
            repo_id=repo_id,
            filename=filename,
            repo_type="dataset",
            token=token,
            local_dir=target_root,
            local_dir_use_symlinks=False, 
            force_download=False
        )
        return "SUCCESS"
    except Exception as e:
        print(f"[ERROR] {filename}: {e}")
        return "ERROR"

def sync_repo(repo_id, token, root_dir, force=False, artist_filter="*", quality_filter="*"):
    safe_name = repo_id.replace("/", "_")
    target_dir = os.path.join(root_dir, safe_name)
    os.makedirs(target_dir, exist_ok=True)
    
    if get_free_space_mb(target_dir) < DISK_SAFE_LIMIT_MB:
        log(f"ğŸ›‘ ç£ç›˜ç©ºé—´ä¸è¶³ {DISK_SAFE_LIMIT_MB}MBï¼Œåœæ­¢ä¸‹è½½ã€‚")
        return

    api = HfApi(token=token)
    
    # ä½¿ç”¨æ–°çš„æ™ºèƒ½è·å–å‡½æ•°
    files_to_download = get_smart_file_list(api, repo_id, artist_filter, quality_filter)
    
    if not files_to_download:
        log("âš ï¸ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶ã€‚")
        return

    log(f"å‡†å¤‡ä¸‹è½½ {len(files_to_download)} ä¸ªæœ€ä¼˜æ–‡ä»¶...")
    
    success_count = 0
    disk_full = False
    
    with ThreadPoolExecutor(max_workers=8) as executor:
        futures = {executor.submit(download_single_file, repo_id, f, token, target_dir): f for f in files_to_download}
        total = len(files_to_download)
        for i, future in enumerate(as_completed(futures)):
            if future.result() == "SUCCESS": success_count += 1
            elif future.result() == "DISK_FULL": 
                disk_full = True
                executor.shutdown(wait=False, cancel_futures=True)
                break
            if i % 20 == 0: print(f"è¿›åº¦: {i}/{total}...", end="\r", flush=True)
                
    print(f"\n") 
    log(f"ä»»åŠ¡ç»“æŸã€‚æˆåŠŸ: {success_count}/{len(files_to_download)}")
    if disk_full: log("ğŸ›‘ è§¦å‘ç£ç›˜ç†”æ–­ï¼Œå·²åœæ­¢ã€‚")

if __name__ == "__main__":
    if len(sys.argv) < 4: sys.exit(0)
    sources = [s.strip() for s in sys.argv[1].split(',') if s.strip()]
    token, root = sys.argv[2], sys.argv[3]
    interval = int(sys.argv[4])
    artist_filter = sys.argv[6] if len(sys.argv) > 6 else "*"
    quality_filter = sys.argv[7] if len(sys.argv) > 7 else "*"

    print(f"[DEBUG] æ™ºèƒ½æ¨¡å¼å¯åŠ¨: ä¼˜é€‰å“è´¨='{quality_filter}'", flush=True)

    for s in sources: 
        sync_repo(s, token, root, force=True, artist_filter=artist_filter, quality_filter=quality_filter)

    log("ç›‘æ§æ¨¡å¼å·²å¯åŠ¨...")
    while True:
        time.sleep(interval)
        for s in sources: 
            sync_repo(s, token, root, force=False, artist_filter=artist_filter, quality_filter=quality_filter)
